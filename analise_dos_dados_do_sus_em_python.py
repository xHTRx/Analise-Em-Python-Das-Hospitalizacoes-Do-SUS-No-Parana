# -*- coding: utf-8 -*-
"""Analise dos dados do SUS em python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fqtl1ViOMAYMam3cRe_fYD7DPomIBP7x
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from scipy.optimize import curve_fit


file_path = 'Hospitaliza√ß√µes pelo SUS_Tabela (1).xlsx' # APENAS O NOME DO ARQUIVO

# Pular as 25 primeiras linhas (skiprows=25)
# header=0 indica que a primeira linha ap√≥s o skip (linha 26 original) √© o cabe√ßalho.
try:
    df_bruto = pd.read_excel(file_path, sheet_name=0, skiprows=25)
except ValueError as e:
    print(f"Erro ao ler o Excel. Tente especificar o nome da aba com 'sheet_name=NomeDaAba': {e}")
    raise

# 1. Limpeza e Sele√ß√£o de Colunas
# As primeiras colunas (A e B) s√£o geralmente identificadores (Munic√≠pio, Regi√£o).
# Os dados num√©ricos de interesse come√ßam na terceira coluna (√≠ndice 2) at√© a P (√≠ndice 15).
df_dados = df_bruto.iloc[:, 2:16].copy()

df_dados.columns = [
    'N_Internacoes_2023', 'N_Internacoes_2024',
    'Gasto_Total_2023', 'Gasto_Total_2024',
    'Gasto_Medio_2023', 'Gasto_Medio_2024',
    'Perm_Media_2023', 'Perm_Media_2024',
    'Taxa_Ocup_2023', 'Taxa_Ocup_2024',
    'Taxa_Mortalidade_2023', 'Taxa_Mortalidade_2024',
    'Obitos_2023', 'Obitos_2024'
]

# 2. Tratamento de Dados
# O argumento 'coerce' transforma valores n√£o num√©ricos (como '#N/A' ou '-' ) em NaN
for col in df_dados.columns:
    df_dados[col] = pd.to_numeric(df_dados[col], errors='coerce')

# Removendo linhas com valores nulos (NaN) para garantir que os modelos de regress√£o funcionem
df_dados.dropna(inplace=True)

print("--- Dados Prontos para Modelagem (Amostra) ---")
print(df_dados.head())
print(f"\nTotal de Linhas ap√≥s Limpeza: {len(df_dados)}")

# Definindo as vari√°veis dependentes (Y)
Y = df_dados['Gasto_Total_2024']

# ----------------------------------------------------------------------
# A) REGRESS√ÉO LINEAR SIMPLES (Gasto Total 2024 vs. N. Interna√ß√µes 2024)
# ----------------------------------------------------------------------
print("="*60)
print("A) REGRESS√ÉO LINEAR SIMPLES")
print("Vari√°vel Independente (X): N. Interna√ß√µes (2024)")
print("Vari√°vel Dependente (Y): Gasto Total (2024)")
print("="*60)

X_simples = df_dados['N_Internacoes_2024']
X_simples = sm.add_constant(X_simples) # Adiciona o intercepto

modelo_linear_simples = sm.OLS(Y, X_simples).fit()
print(modelo_linear_simples.summary())

# Plotagem
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.scatter(df_dados['N_Internacoes_2024'], Y, alpha=0.6)
plt.plot(df_dados['N_Internacoes_2024'], modelo_linear_simples.predict(X_simples), color='red')
plt.title('Regress√£o Linear Simples')
plt.xlabel('N. Interna√ß√µes (2024)')
plt.ylabel('Gasto Total (2024)')


# ----------------------------------------------------------------------
# B) REGRESS√ÉO LINEAR M√öLTIPLA (Gasto Total 2024 vs. N. Interna√ß√µes, Ocupa√ß√£o e Mortalidade 2024)
# ----------------------------------------------------------------------
print("\n"+"="*60)
print("B) REGRESS√ÉO LINEAR M√öLTIPLA")
print("Vari√°veis (X): N. Interna√ß√µes, Taxa Ocup., Taxa Mortalidade (2024)")
print("Vari√°vel (Y): Gasto Total (2024)")
print("="*60)

X_multi = df_dados[['N_Internacoes_2024', 'Taxa_Ocup_2024', 'Taxa_Mortalidade_2024']]
X_multi = sm.add_constant(X_multi)

modelo_linear_multipla = sm.OLS(Y, X_multi).fit()
print(modelo_linear_multipla.summary())

# Plotagem dos Res√≠duos (para M√∫ltipla)
residuos = modelo_linear_multipla.resid

plt.subplot(1, 2, 2)
plt.scatter(modelo_linear_multipla.fittedvalues, residuos, alpha=0.6)
plt.axhline(0, color='red', linestyle='--')
plt.title('Res√≠duos vs. Valores Previstos (Reg. M√∫ltipla)')
plt.xlabel('Valores Previstos')
plt.ylabel('Res√≠duos')

plt.tight_layout()
plt.show()

# Vari√°veis de entrada para Regress√£o N√£o Linear (usaremos N. Interna√ß√µes 2024)
X_nao_linear = df_dados['N_Internacoes_2024'].values.reshape(-1, 1)
Y = df_dados['Gasto_Total_2024'].values

# ----------------------------------------------------------------------
# C) REGRESS√ÉO N√ÉO LINEAR (PAR√ÅBOLA - Polinomial de Grau 2)
# ----------------------------------------------------------------------
print("="*60)
print("C) REGRESS√ÉO N√ÉO LINEAR (PAR√ÅBOLA - Polinomial de Grau 2)")
print("="*60)

# 1. Transformar X em [X, X^2]
poly_features = PolynomialFeatures(degree=2)
X_poly_transformed = poly_features.fit_transform(X_nao_linear)

# 2. Treinar modelo linear nos termos transformados
modelo_parabola = LinearRegression()
modelo_parabola.fit(X_poly_transformed, Y)

# 3. C√°lculo do R¬≤
r_sq_poly = modelo_parabola.score(X_poly_transformed, Y)
print(f"R¬≤ (Par√°bola): {r_sq_poly:.4f}")

# Plotagem para a Par√°bola
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.scatter(X_nao_linear, Y, label='Dados Reais', alpha=0.6)

# Gerar previs√µes para plotagem suave
X_fit = np.linspace(X_nao_linear.min(), X_nao_linear.max(), 100).reshape(-1, 1)
X_fit_transformed = poly_features.transform(X_fit)
Y_pred_parabola = modelo_parabola.predict(X_fit_transformed)

plt.plot(X_fit, Y_pred_parabola, color='green', label='Regress√£o Polinomial (Par√°bola)')
plt.title('Regress√£o N√£o Linear (Par√°bola)')
plt.xlabel('N. Interna√ß√µes (2024)')
plt.ylabel('Gasto Total (2024)')
plt.legend()


# ----------------------------------------------------------------------
# D) REGRESS√ÉO N√ÉO LINEAR (EXPONENCIAL)
# ----------------------------------------------------------------------
print("\n"+"="*60)
print("D) REGRESS√ÉO N√ÉO LINEAR (EXPONENCIAL)")
print("="*60)

# Fun√ß√£o Exponencial: y = a * exp(b * x)
def func_exponencial(x, a, b):
    return a * np.exp(b * x) + 1e-6 # Adicionado um offset pequeno para estabilidade

try:
    # Estima os par√¢metros (a, b). p0 ajustado para dados hospitalares que podem ter grande varia√ß√£o.
    popt, pcov = curve_fit(func_exponencial, X_nao_linear.flatten(), Y, p0=[1, 1e-6], maxfev=5000)

    a_opt, b_opt = popt

    print(f"Par√¢metros Exponenciais √ìtimos (a, b): {a_opt:.4e}, {b_opt:.4e}")

    Y_pred_exp = func_exponencial(X_nao_linear.flatten(), a_opt, b_opt)

    # C√°lculo do R¬≤ (manual para curve_fit)
    ss_total = np.sum((Y - np.mean(Y))**2)
    ss_residual = np.sum((Y - Y_pred_exp)**2)
    r_sq_exp = 1 - (ss_residual / ss_total)

    print(f"R¬≤ (Exponencial): {r_sq_exp:.4f}")

    # Plotagem
    plt.subplot(1, 2, 2)
    plt.scatter(X_nao_linear, Y, label='Dados Reais', alpha=0.6)
    plt.plot(X_nao_linear, Y_pred_exp, color='orange', label='Regress√£o Exponencial')
    plt.title('Regress√£o N√£o Linear (Exponencial)')
    plt.xlabel('N. Interna√ß√µes (2024)')
    plt.ylabel('Gasto Total (2024)')
    plt.legend()

except RuntimeError:
    print("ERRO: N√£o foi poss√≠vel encontrar os par√¢metros ideais para o modelo Exponencial. Tente ajustar o p0.")

plt.tight_layout()
plt.show()

# ======================================================================
# E) REQUISITO 2: COMPARA√á√ÉO DE M√âTODOS DE OTIMIZA√á√ÉO NA PAR√ÅBOLA
# ======================================================================
print("\n" + "="*60)
print("E) REQUISITO 2.2: COMPARA√á√ÉO DE OTIMIZADORES NA REGRESS√ÉO PAR√ÅBOLA")
print("="*60)

from scipy.optimize import curve_fit
from sklearn.metrics import mean_squared_error, r2_score
# O resto das bibliotecas (numpy, pandas, matplotlib) j√° est√£o importadas

# Definir a fun√ß√£o Par√°bola novamente (agora para uso com curve_fit e PyMC)
def func_parabola(x, b0, b1, b2):
    return b0 + b1 * x + b2 * x**2

X_flat = X_nao_linear.flatten()
Y_real = Y

# Tabela para armazenar os resultados da compara√ß√£o
resultados_otimizacao_parabola = pd.DataFrame(columns=['Modelo', 'M√©todo', 'R¬≤', 'RMSE'])

# --- FUN√á√ÉO AUXILIAR PARA CALCULAR M√âTRICAS ---
def calcular_metricas(Y_real, Y_pred, modelo, metodo):
    r2 = r2_score(Y_real, Y_pred)
    rmse = np.sqrt(mean_squared_error(Y_real, Y_pred))
    return pd.DataFrame([{'Modelo': modelo, 'M√©todo': metodo, 'R¬≤': r2, 'RMSE': rmse}])


# ======================================================================
# 1. M√≠nimos Quadrados N√ÉO-LINEAR (LM - Algoritmo de Levenberg-Marquart)
# ======================================================================
print("1. Estimando com Levenberg-Marquardt (LM)")
try:
    popt_lm, pcov_lm = curve_fit(func_parabola, X_flat, Y_real, p0=[1e5, 1, 1e-4], method='lm', maxfev=5000)
    Y_pred_lm = func_parabola(X_flat, *popt_lm)
    resultados_otimizacao_parabola = pd.concat([resultados_otimizacao_parabola, calcular_metricas(Y_real, Y_pred_lm, 'Par√°bola', 'LM (Levenberg-Marquart)')], ignore_index=True)
except Exception as e:
    print(f"Erro em LM: {e}")

# ======================================================================
# 2. M√©todo de Gauss-Newton (Trust Region Reflective - TRF)
#    TRF √© um m√©todo de segunda ordem que serve como proxy robusto do Gauss-Newton.
# ======================================================================
print("2. Estimando com Trust Region Reflective (Proxy para Gauss-Newton)")
try:
    popt_trf, pcov_trf = curve_fit(func_parabola, X_flat, Y_real, p0=[1e5, 1, 1e-4], method='trf', maxfev=5000)
    Y_pred_trf = func_parabola(X_flat, *popt_trf)
    resultados_otimizacao_parabola = pd.concat([resultados_otimizacao_parabola, calcular_metricas(Y_real, Y_pred_trf, 'Par√°bola', 'TRF (Gauss-Newton Proxy)')], ignore_index=True)
except Exception as e:
    print(f"Erro em TRF: {e}")

# ======================================================================
# 3. M√≠nimos Quadrados ORDIN√ÅRIOS (OLS)
#    J√° implementado no Bloco C. Recalculamos aqui para a tabela de compara√ß√£o.
# ======================================================================
print("3. Incluindo OLS (M√≠nimos Quadrados Ordin√°rios)")
# O resultado √© o mesmo do Bloco C
Y_pred_ols_parabola = modelo_parabola.predict(X_poly_transformed) # Usando o modelo treinado em C
resultados_otimizacao_parabola = pd.concat([resultados_otimizacao_parabola, calcular_metricas(Y_real, Y_pred_ols_parabola, 'Par√°bola', 'OLS (M√≠n. Quadrados Linear)')], ignore_index=True)

# ======================================================================
# 4. M√°xima Verossimilhan√ßa (MLE)
#    OBS: MLE n√£o √© comum para modelos cont√≠nuos simples como a Par√°bola.
#    Usamos aqui o resultado da Regress√£o Log√≠stica (Logit) como PROXY,
#    pois √© o modelo mais direto em Python que usa MLE, ou ignoramos se n√£o existir.
#    *** VAMOS IGNORAR MLE AQUI, MENCIONANDO NO RELAT√ìRIO QUE LOGIT USA MLE. ***
# ======================================================================


# ======================================================================
# 5. M√©todos Bayesianos (MCMC com PyMC)
# ======================================================================
print("4. Estimando com M√©todos Bayesianos (PyMC)")

try:
    import pymc as pm

    with pm.Model() as bayesian_model:
        # Priors
        b0_prior = pm.Normal("b0", mu=Y_real.mean(), sigma=Y_real.std())
        b1_prior = pm.Normal("b1", mu=0, sigma=1)
        b2_prior = pm.Normal("b2", mu=0, sigma=1e-5)

        # Fun√ß√£o Par√°bola
        mu = pm.Deterministic("mu", func_parabola(X_flat, b0_prior, b1_prior, b2_prior))

        # Vari√¢ncia (Likelihood)
        sigma = pm.HalfCauchy("sigma", beta=100)
        Y_obs = pm.Normal("Y_obs", mu=mu, sigma=sigma, observed=Y_real)

        trace = pm.sample(draws=1000, tune=1000, chains=2, target_accept=0.95, random_seed=42, return_incomplete_trace=True)

    b0_bay = trace.posterior['b0'].mean().item()
    b1_bay = trace.posterior['b1'].mean().item()
    b2_bay = trace.posterior['b2'].mean().item()

    Y_pred_bay = func_parabola(X_flat, b0_bay, b1_bay, b2_bay)

    resultados_otimizacao_parabola = pd.concat([resultados_otimizacao_parabola, calcular_metricas(Y_real, Y_pred_bay, 'Par√°bola', 'Bayesiano (MCMC)')], ignore_index=True)
    print(f"Par√¢metros Bayesianos (b0, b1, b2): {b0_bay:.0f}, {b1_bay:.4f}, {b2_bay:.4e}")

except ImportError:
    print("\nAVISO: O m√©todo BAYESIANO (PyMC) requer a instala√ß√£o. Pulando esta etapa.")
except Exception as e:
    print(f"Erro no modelo Bayesiano: {e}")

# ======================================================================
# 6. Exibi√ß√£o e Compara√ß√£o Final
# ======================================================================
print("\n"+"="*60)
print("RELAT√ìRIO DE COMPARA√á√ÉO DE OTIMIZADORES NA REGRESS√ÉO PAR√ÅBOLA")
print("="*60)
print(resultados_otimizacao_parabola.to_markdown(index=False, floatfmt=".4f"))


# Plotagem da Compara√ß√£o
plt.figure(figsize=(10, 6))
plt.scatter(X_flat, Y_real, label='Dados Reais', alpha=0.3)

for index, row in resultados_otimizacao_parabola.iterrows():
    color = {'LM (Levenberg-Marquart)': 'red', 'TRF (Gauss-Newton Proxy)': 'green', 'OLS (M√≠n. Quadrados Linear)': 'blue', 'Bayesiano (MCMC)': 'purple'}.get(row['M√©todo'], 'gray')
    label = f"{row['M√©todo'].split('(')[0].strip()} (R¬≤: {row['R¬≤']:.4f})"

    X_fit_plot = np.linspace(X_flat.min(), X_flat.max(), 100)

    # Obter os par√¢metros corretos para plotagem
    if row['M√©todo'] == 'Bayesiano (MCMC)':
        # Usa os par√¢metros b0_bay, b1_bay, b2_bay calculados
        if 'b0_bay' in locals():
            Y_fit_plot = func_parabola(X_fit_plot, b0_bay, b1_bay, b2_bay)
        else:
            continue
    elif row['M√©todo'] == 'OLS (M√≠n. Quadrados Linear)':
        # Usa o modelo OLS treinado no Bloco C
        Y_fit_plot = modelo_parabola.predict(poly_features.transform(X_fit_plot.reshape(-1, 1)))
    else:
        # Re-estima os par√¢metros usando curve_fit (LM e TRF)
        method_name = 'lm' if 'LM' in row['M√©todo'] else 'trf'
        try:
            popt_plot, _ = curve_fit(func_parabola, X_flat, Y_real, p0=[1e5, 1, 1e-4], method=method_name, maxfev=5000)
            Y_fit_plot = func_parabola(X_fit_plot, *popt_plot)
        except Exception:
             continue # Se der erro, n√£o plota

    plt.plot(X_fit_plot, Y_fit_plot, color=color, linewidth=2, label=label)

plt.title('Compara√ß√£o dos M√©todos de Otimiza√ß√£o na Regress√£o Par√°bola')
plt.xlabel('N. Interna√ß√µes (2024)')
plt.ylabel('Gasto Total (2024)')
plt.legend()
plt.grid(True, linestyle='--')
plt.ticklabel_format(style='plain', axis='y')
plt.show()

print("\n--- O Bloco E atende o Requisito 2 de compara√ß√£o (LM, TRF/Gauss-Newton, Bayesiano e OLS). ---")

# ======================================================================
# F) REQUISITO 2: COMPARA√á√ÉO DE TODOS OS 5 M√âTODOS NA REGRESS√ÉO PAR√ÅBOLA
# ======================================================================
print("\n" + "="*60)
print("F) REQUISITO 2.2: COMPARA√á√ÉO DE TODOS OS 5 OTIMIZADORES NA PAR√ÅBOLA")
print("="*60)

from scipy.optimize import curve_fit, minimize
from sklearn.metrics import mean_squared_error, r2_score
from scipy.stats import norm

# --- Dados de Entrada (garantindo que est√£o planos) ---
X_flat = X_nao_linear.flatten()
Y_real = Y

# --- Tabela Final de Compara√ß√£o ---
resultados_otimizacao_parabola_final = pd.DataFrame(columns=['Modelo', 'M√©todo', 'R¬≤', 'RMSE'])

# --- FUN√á√ÉO AUXILIAR PARA M√âTRICAS (inalterada) ---
def calcular_metricas(Y_real, Y_pred, modelo, metodo):
    r2 = r2_score(Y_real, Y_pred)
    rmse = np.sqrt(mean_squared_error(Y_real, Y_pred))
    return pd.DataFrame([{'Modelo': modelo, 'M√©todo': metodo, 'R¬≤': r2, 'RMSE': rmse}])

# --- Fun√ß√µes do Modelo Par√°bola ---
def func_parabola(x, b0, b1, b2):
    return b0 + b1 * x + b2 * x**2

# ======================================================================
# PARTE 1: MIN. QUADRADOS (LM, TRF) E OLS
# ======================================================================

# 1. M√≠nimos Quadrados ORDIN√ÅRIOS (OLS)
print("1. OLS (M√≠n. Quadrados Linear) - Baseline")
Y_pred_ols = modelo_parabola.predict(X_poly_transformed) # Usando o modelo treinado em C
resultados_otimizacao_parabola_final = pd.concat([resultados_otimizacao_parabola_final, calcular_metricas(Y_real, Y_pred_ols, 'Par√°bola', 'OLS (M√≠n. Quadrados)')], ignore_index=True)

# 2. Algoritmo de Levenberg-Marquart (LM)
print("2. LM (Levenberg-Marquart)")
try:
    popt_lm, _ = curve_fit(func_parabola, X_flat, Y_real, p0=[1e5, 1, 1e-4], method='lm', maxfev=5000)
    Y_pred_lm = func_parabola(X_flat, *popt_lm)
    resultados_otimizacao_parabola_final = pd.concat([resultados_otimizacao_parabola_final, calcular_metricas(Y_real, Y_pred_lm, 'Par√°bola', 'LM (Levenberg-Marquart)')], ignore_index=True)
except Exception as e:
    print(f"Erro em LM: {e}")

# 3. M√©todo de Gauss-Newton (TRF Proxy)
print("3. TRF (Gauss-Newton Proxy)")
try:
    popt_trf, _ = curve_fit(func_parabola, X_flat, Y_real, p0=[1e5, 1, 1e-4], method='trf', maxfev=5000)
    Y_pred_trf = func_parabola(X_flat, *popt_trf)
    resultados_otimizacao_parabola_final = pd.concat([resultados_otimizacao_parabola_final, calcular_metricas(Y_real, Y_pred_trf, 'Par√°bola', 'TRF (Gauss-Newton)')], ignore_index=True)
except Exception as e:
    print(f"Erro em TRF: {e}")


# ======================================================================
# PARTE 2: M√ÅXIMA VEROSSIMILHAN√áA (MLE) - Implementa√ß√£o Customizada
# ======================================================================
print("4. M√°xima Verossimilhan√ßa (MLE) - Customizada")
# Fun√ß√£o de Log-Verossimilhan√ßa (Log-Likelihood) Negativa (para ser MINIMIZADA)
def neg_log_likelihood_parabola(params, x, y):
    b0, b1, b2, sigma = params
    mu = func_parabola(x, b0, b1, b2)
    # Assume erro normal (Gaussiano)
    log_likelihood = np.sum(norm.logpdf(y, loc=mu, scale=sigma))
    return -log_likelihood

try:
    # Chute inicial: [b0, b1, b2, sigma]
    # Usamos os par√¢metros OLS (b0, b1) e a m√©dia do erro quadr√°tico (sigma)
    initial_params_mle = np.append(modelo_parabola.intercept_, modelo_parabola.coef_[1:])
    initial_params_mle = np.append(initial_params_mle, np.sqrt(mean_squared_error(Y_real, Y_pred_ols)))

    # Otimiza√ß√£o: Minimiza a Log-Likelihood Negativa
    mle_results = minimize(neg_log_likelihood_parabola, initial_params_mle, args=(X_flat, Y_real), method='Nelder-Mead')

    b0_mle, b1_mle, b2_mle, sigma_mle = mle_results.x
    Y_pred_mle = func_parabola(X_flat, b0_mle, b1_mle, b2_mle)

    # Se a otimiza√ß√£o MLE for bem-sucedida, deve convergir para OLS!
    resultados_otimizacao_parabola_final = pd.concat([resultados_otimizacao_parabola_final, calcular_metricas(Y_real, Y_pred_mle, 'Par√°bola', 'MLE')], ignore_index=True)

except Exception as e:
    print(f"Erro no modelo MLE: {e}")


# ======================================================================
# PARTE 3: M√âTODOS BAYESIANOS (MCMC)
# ======================================================================
print("5. M√©todos Bayesianos (PyMC)")

try:
    import pymc as pm

    with pm.Model() as bayesian_model:
        # Priors
        b0_prior = pm.Normal("b0", mu=Y_real.mean(), sigma=Y_real.std())
        b1_prior = pm.Normal("b1", mu=0, sigma=1)
        b2_prior = pm.Normal("b2", mu=0, sigma=1e-5)

        mu = pm.Deterministic("mu", func_parabola(X_flat, b0_prior, b1_prior, b2_prior))

        sigma = pm.HalfCauchy("sigma", beta=100)
        Y_obs = pm.Normal("Y_obs", mu=mu, sigma=sigma, observed=Y_real)

        trace = pm.sample(draws=1000, tune=1000, chains=2, target_accept=0.95, random_seed=42, return_incomplete_trace=True)

    b0_bay = trace.posterior['b0'].mean().item()
    b1_bay = trace.posterior['b1'].mean().item()
    b2_bay = trace.posterior['b2'].mean().item()

    Y_pred_bay = func_parabola(X_flat, b0_bay, b1_bay, b2_bay)

    resultados_otimizacao_parabola_final = pd.concat([resultados_otimizacao_parabola_final, calcular_metricas(Y_real, Y_pred_bay, 'Par√°bola', 'Bayesiano (MCMC)')], ignore_index=True)
    print(f"Par√¢metros Bayesianos (b0, b1, b2): {b0_bay:.0f}, {b1_bay:.4f}, {b2_bay:.4e}")

except ImportError:
    print("\nAVISO: O m√©todo BAYESIANO (PyMC) requer a instala√ß√£o. Pulando esta etapa.")
except Exception as e:
    print(f"Erro no modelo Bayesiano: {e}")


# ======================================================================
# 6. Exibi√ß√£o e Compara√ß√£o Final (REQUISITO 2.4)
# ======================================================================
print("\n"+"="*60)
print("RELAT√ìRIO FINAL DE COMPARA√á√ÉO (MODELO PAR√ÅBOLA COM OS 5 M√âTODOS)")
print("="*60)
print(resultados_otimizacao_parabola_final.to_markdown(index=False, floatfmt=".4f"))

# Plotagem da Compara√ß√£o
# (Este gr√°fico final precisar√° ser adaptado para mostrar as 5 curvas)

# Aqui voc√™ pode optar por plotar apenas as 3 curvas mais relevantes (OLS/LM/TRF, MLE e Bayesiano)
# j√° que OLS, LM e MLE devem ser visivelmente id√™nticas se a converg√™ncia for perfeita.
plt.figure(figsize=(10, 6))
plt.scatter(X_flat, Y_real, label='Dados Reais', alpha=0.3)

# Plot OLS/LM/TRF/MLE (Devem ser iguais, plotamos apenas 1)
Y_fit_ols_plot = modelo_parabola.predict(poly_features.transform(np.linspace(X_flat.min(), X_flat.max(), 100).reshape(-1, 1)))
plt.plot(np.linspace(X_flat.min(), X_flat.max(), 100), Y_fit_ols_plot, color='blue', linewidth=3, label=f'M√çN. QUADRADOS (R¬≤: {r_sq_poly:.4f})')

# Plot Bayesiano
if 'b0_bay' in locals():
    Y_fit_bay_plot = func_parabola(np.linspace(X_flat.min(), X_flat.max(), 100), b0_bay, b1_bay, b2_bay)
    plt.plot(np.linspace(X_flat.min(), X_flat.max(), 100), Y_fit_bay_plot, color='purple', linewidth=2, linestyle='--', label=f'Bayesiano (R¬≤: {resultados_otimizacao_parabola_final[resultados_otimizacao_parabola_final.M√©todo.str.contains("Bayesiano")]["R¬≤"].iloc[0]:.4f})')

plt.title('Regress√£o Par√°bola: Compara√ß√£o Otimizadores (M√≠n. Quadrados vs. Bayesiano)')
plt.xlabel('N. Interna√ß√µes (2024)')
plt.ylabel('Gasto Total (2024)')
plt.legend()
plt.grid(True, linestyle='--')
plt.ticklabel_format(style='plain', axis='y')
plt.show()

print("\n--- O Bloco F agora cobre TODOS os 5 m√©todos exigidos na Regress√£o Par√°bola. ---")

# C√©lula 5: Regress√£o Log√≠stica e Pot√™ncia

# ----------------------------------------------------------------------
# E) REGRESS√ÉO N√ÉO LINEAR (POT√äNCIA)
# Forma: Y = a * X^b
# Linearizada: log(Y) = log(a) + b * log(X)
# ----------------------------------------------------------------------
print("="*60)
print("E) REGRESS√ÉO N√ÉO LINEAR (POT√äNCIA)")
print("Vari√°vel Independente (X): N. Interna√ß√µes (2024)")
print("Vari√°vel Dependente (Y): Gasto Total (2024)")
print("="*60)

# Para evitar log(0) ou log(negativo), filtramos os dados (embora improv√°vel para N. Interna√ß√µes)
df_potencia = df_dados[
    (df_dados['N_Internacoes_2024'] > 0) &
    (df_dados['Gasto_Total_2024'] > 0)
].copy()

# 1. Transformar as vari√°veis para o modelo linear (log-log)
X_log = np.log(df_potencia['N_Internacoes_2024'])
Y_log = np.log(df_potencia['Gasto_Total_2024'])
X_log = sm.add_constant(X_log) # Adiciona o intercepto

# 2. Treinar o modelo OLS nos termos logar√≠tmicos
modelo_potencia_log = sm.OLS(Y_log, X_log).fit()
print(modelo_potencia_log.summary())

# Coeficientes: b √© o slope, a √© exp(intercepto)
b_potencia = modelo_potencia_log.params[1]
log_a_potencia = modelo_potencia_log.params[0]
a_potencia = np.exp(log_a_potencia)

print(f"\nPar√¢metros do Modelo de Pot√™ncia (Y = a * X^b):")
print(f"a = exp(Intercepto) = {a_potencia:.2f}")
print(f"b = Coeficiente de log(X) = {b_potencia:.2f}")


# ----------------------------------------------------------------------
# F) REGRESS√ÉO N√ÉO LINEAR (LOG√çSTICA - Classifica√ß√£o Bin√°ria)
# *Requer uma vari√°vel dependente bin√°ria (0 ou 1)*
# ----------------------------------------------------------------------
print("\n"+"="*60)
print("F) REGRESS√ÉO N√ÉO LINEAR (LOG√çSTICA - Simula√ß√£o de Alto Gasto)")
print("Vari√°vel Independente (X): N. Interna√ß√µes (2024)")
print("Vari√°vel Dependente (Y): Gasto Alto (1) vs. Gasto Baixo (0)")
print("="*60)

# 1. Criar a vari√°vel bin√°ria (Y_binario): 1 se o gasto est√° acima da m√©dia, 0 caso contr√°rio.
limite_gasto = df_dados['Gasto_Total_2024'].mean()
Y_logistica = (df_dados['Gasto_Total_2024'] > limite_gasto).astype(int)

X_logistica = df_dados[['N_Internacoes_2024', 'Taxa_Ocup_2024']]
X_logistica = sm.add_constant(X_logistica)

# 2. Treinar o modelo Logit (Regress√£o Log√≠stica)
modelo_logistica = sm.Logit(Y_logistica, X_logistica).fit()

print(modelo_logistica.summary())

# Plotagem da Log√≠stica (Probabilidade vs N. Interna√ß√µes)
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)

# Gerar previs√µes de probabilidade
X_plot = df_dados['N_Internacoes_2024'].sort_values()
# Criar DataFrame de teste para a previs√£o, mantendo as outras vari√°veis na m√©dia
X_teste = pd.DataFrame({
    'const': 1,
    'N_Internacoes_2024': X_plot,
    'Taxa_Ocup_2024': df_dados['Taxa_Ocup_2024'].mean()
})
Y_prob = modelo_logistica.predict(X_teste)

plt.scatter(df_dados['N_Internacoes_2024'], Y_logistica, alpha=0.1, label='Dados Reais (0 ou 1)')
plt.plot(X_plot, Y_prob, color='purple', label='Curva Log√≠stica (Probabilidade)')
plt.axvline(df_dados[Y_logistica == 1]['N_Internacoes_2024'].min(), color='red', linestyle='--', label='Menor N. Interna√ß√µes com Alto Gasto')
plt.title('Regress√£o Log√≠stica (Probabilidade de Alto Gasto)')
plt.xlabel('N. Interna√ß√µes (2024)')
plt.ylabel('Probabilidade de Gasto > M√©dia')
plt.legend()
plt.grid(True, linestyle='--')

plt.tight_layout()
plt.show()

# Relembrando as vari√°veis de R¬≤ e Modelos do seu output:
# modelo_linear_simples.rsquared = 0.990
# r_sq_poly = 0.9932
# r_sq_exp = 0.7955

# Assumindo que as vari√°veis do C√©lula 4 est√£o no escopo:
# df_dados, X_nao_linear, Y, X_fit, Y_pred_parabola, Y_pred_exp, modelo_linear_simples

import matplotlib.pyplot as plt
import numpy as np

fig, axes = plt.subplots(1, 3, figsize=(18, 5))
fig.suptitle('Dashboard de Modelos de Regress√£o: Gasto Total (Y) vs. N. Interna√ß√µes (X)', fontsize=16)

# --- 1. Linear Simples (R¬≤: 0.990) ---
axes[0].scatter(df_dados['N_Internacoes_2024'], df_dados['Gasto_Total_2024'], label='Dados Reais', alpha=0.6, s=15)
X_linear_plot = sm.add_constant(df_dados['N_Internacoes_2024'])
axes[0].plot(df_dados['N_Internacoes_2024'], modelo_linear_simples.predict(X_linear_plot), color='red', linewidth=3, label=f'Linear (R¬≤=0.9900)')
axes[0].set_title('Linear Simples')
axes[0].set_xlabel('N. Interna√ß√µes (2024)')
axes[0].set_ylabel('Gasto Total (2024)')
axes[0].legend()
axes[0].grid(True, linestyle='--')
axes[0].ticklabel_format(style='plain', axis='y') # Tira a nota√ß√£o cient√≠fica do Y


# --- 2. Par√°bola (R¬≤: 0.9932) ---
axes[1].scatter(X_nao_linear, Y, label='Dados Reais', alpha=0.6, s=15)
axes[1].plot(X_fit, Y_pred_parabola, color='green', linewidth=3, label=f'Polinomial (R¬≤=0.9932)')
axes[1].set_title('N√£o Linear: Par√°bola (Grau 2)')
axes[1].set_xlabel('N. Interna√ß√µes (2024)')
axes[1].legend()
axes[1].grid(True, linestyle='--')
axes[1].ticklabel_format(style='plain', axis='y')


# --- 3. Exponencial (R¬≤: 0.7955) ---
axes[2].scatter(X_nao_linear, Y, label='Dados Reais', alpha=0.6, s=15)
axes[2].plot(X_nao_linear, Y_pred_exp, color='orange', linewidth=3, label=f'Exponencial (R¬≤=0.7955)')
axes[2].set_title('N√£o Linear: Exponencial')
axes[2].set_xlabel('N. Interna√ß√µes (2024)')
axes[2].legend()
axes[2].grid(True, linestyle='--')
axes[2].ticklabel_format(style='plain', axis='y')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# C√©lula 6 (AJUSTADA): Visualiza√ß√£o da Regress√£o Pot√™ncia e Log√≠stica

import matplotlib.pyplot as plt
import numpy as np
import statsmodels.api as sm
import pandas as pd

# Vari√°veis j√° calculadas (assumindo que as c√©lulas anteriores foram executadas):
# df_dados, modelo_logistica, df_potencia, a_potencia, b_potencia

fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle('Visualiza√ß√£o dos Modelos de Regress√£o N√£o Linear Faltantes', fontsize=16)

# ======================================================================
# 1. REGRESS√ÉO DE POT√äNCIA (Y vs X) - Mantido inalterado
# ======================================================================

# Vari√°veis do modelo de pot√™ncia
X_pot = df_potencia['N_Internacoes_2024'].values
Y_pot = df_potencia['Gasto_Total_2024'].values
# Previs√£o baseada nos par√¢metros 'a_potencia' e 'b_potencia'
Y_pred_potencia = a_potencia * (X_pot ** b_potencia)
r_sq_potencia = modelo_potencia_log.rsquared

# Plotagem
axes[0].scatter(X_pot, Y_pot, label='Dados Reais', alpha=0.6, s=15)
axes[0].plot(X_pot, Y_pred_potencia, color='purple', linewidth=3,
             label=f'Pot√™ncia (R¬≤={r_sq_potencia:.4f}) \n Y = {a_potencia:.0f} * X^{b_potencia:.2f}')
axes[0].set_title('Regress√£o N√£o Linear: Pot√™ncia')
axes[0].set_xlabel('N. Interna√ß√µes (2024)')
axes[0].set_ylabel('Gasto Total (2024)')
axes[0].legend()
axes[0].grid(True, linestyle='--')
axes[0].ticklabel_format(style='plain', axis='y')


# ======================================================================
# 2. REGRESS√ÉO LOG√çSTICA (ESCALA AJUSTADA DE 0 a 10)
# ======================================================================

# Reconstruir X_teste e Y_prob
X_plot_log = df_dados['N_Internacoes_2024'].sort_values()
X_teste_log = pd.DataFrame({
    'const': 1,
    'N_Internacoes_2024': X_plot_log,
    'Taxa_Ocup_2024': df_dados['Taxa_Ocup_2024'].mean()
})
Y_prob_log = modelo_logistica.predict(X_teste_log)
Y_logistica_scatter = (df_dados['Gasto_Total_2024'] > df_dados['Gasto_Total_2024'].mean()).astype(int)

# ‚≠êÔ∏è AJUSTE AQUI: Multiplicar a probabilidade por 10
Y_prob_log_escala = Y_prob_log * 10
Y_logistica_scatter_escala = Y_logistica_scatter * 10


# Plotagem
axes[1].scatter(df_dados['N_Internacoes_2024'], Y_logistica_scatter_escala,
                alpha=0.1, s=15, color='gray', label='Alto Gasto (10) ou Baixo Gasto (0)')
axes[1].plot(X_plot_log, Y_prob_log_escala, color='red', linewidth=3,
             label=f'Curva Log√≠stica (Pseudo R¬≤={modelo_logistica.prsquared:.4f})')

axes[1].set_title('Regress√£o Log√≠stica (Probabilidade de Alto Gasto)')
axes[1].set_xlabel('N. Interna√ß√µes (2024)')
# ‚≠êÔ∏è R√≥tulo do eixo Y ajustado
axes[1].set_ylabel('Probabilidade Ajustada (Escala 0 a 10)')
axes[1].set_ylim(-0.5, 10.5) # Limite do eixo Y ajustado para 0 a 10
axes[1].legend()
axes[1].grid(True, linestyle='--')

plt.tight_layout()
plt.show()

# C√ìDIGO PYTHON DO DASHBOARD



import matplotlib.pyplot as plt
import numpy as np
import statsmodels.api as sm
import pandas as pd


# === DASHBOARD 1: Compara√ß√£o dos Melhores Modelos Cont√≠nuos (Linear, Par√°bola, Exponencial) ===

fig1, axes1 = plt.subplots(1, 3, figsize=(18, 5))
fig1.suptitle('Dashboard de Compara√ß√£o de Modelos de Regress√£o Cont√≠nua', fontsize=16)


# 1. Linear Simples

axes1[0].scatter(df_dados['N_Internacoes_2024'], df_dados['Gasto_Total_2024'], label='Dados Reais', alpha=0.6, s=15)
X_linear_plot = sm.add_constant(df_dados['N_Internacoes_2024'])
axes1[0].plot(df_dados['N_Internacoes_2024'], modelo_linear_simples.predict(X_linear_plot), color='red', linewidth=3, label=f'Linear (R¬≤=0.9900)')
axes1[0].set_title('Regress√£o Linear Simples')
axes1[0].set_xlabel('N. Interna√ß√µes (2024)')
axes1[0].set_ylabel('Gasto Total (2024)')
axes1[0].legend()
axes1[0].grid(True, linestyle='--')
axes1[0].ticklabel_format(style='plain', axis='y')



# 2. Par√°bola (Polinomial Grau 2)

axes1[1].scatter(X_nao_linear, Y, label='Dados Reais', alpha=0.6, s=15)
axes1[1].plot(X_fit, Y_pred_parabola, color='green', linewidth=3, label=f'Polinomial (R¬≤=0.9932)')
axes1[1].set_title('N√£o Linear: Par√°bola (Melhor Ajuste)')
axes1[1].set_xlabel('N. Interna√ß√µes (2024)')
axes1[1].legend()
axes1[1].grid(True, linestyle='--')
axes1[1].ticklabel_format(style='plain', axis='y')



# 3. Exponencial

axes1[2].scatter(X_nao_linear, Y, label='Dados Reais', alpha=0.6, s=15)
axes1[2].plot(X_nao_linear, Y_pred_exp, color='orange', linewidth=3, label=f'Exponencial (R¬≤=0.7955)')
axes1[2].set_title('N√£o Linear: Exponencial (Pior Ajuste)')
axes1[2].set_xlabel('N. Interna√ß√µes (2024)')
axes1[2].legend()
axes1[2].grid(True, linestyle='--')
axes1[2].ticklabel_format(style='plain', axis='y')


plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()


# === DASHBOARD 2: Modelos Pot√™ncia e Log√≠stica ===

fig2, axes2 = plt.subplots(1, 2, figsize=(15, 6))
fig2.suptitle('Visualiza√ß√£o dos Modelos Log√≠stica e Pot√™ncia', fontsize=16)


# 1. Regress√£o de Pot√™ncia

X_pot = df_potencia['N_Internacoes_2024'].values
Y_pot = df_potencia['Gasto_Total_2024'].values
Y_pred_potencia = a_potencia * (X_pot ** b_potencia)
r_sq_potencia = modelo_potencia_log.rsquared



axes2[0].scatter(X_pot, Y_pot, label='Dados Reais', alpha=0.6, s=15)
axes2[0].plot(X_pot, Y_pred_potencia, color='purple', linewidth=3,
label=f'Pot√™ncia (R¬≤={r_sq_potencia:.4f}) \n Y = {a_potencia:.0f} * X^{b_potencia:.2f}')
axes2[0].set_title('Regress√£o N√£o Linear: Pot√™ncia')
axes2[0].set_xlabel('N. Interna√ß√µes (2024)')
axes2[0].set_ylabel('Gasto Total (2024)')
axes2[0].legend()
axes2[0].grid(True, linestyle='--')
axes2[0].ticklabel_format(style='plain', axis='y')



# 2. Regress√£o Log√≠stica (Escala 0 a 10)

X_plot_log = df_dados['N_Internacoes_2024'].sort_values()
X_teste_log = pd.DataFrame({
    'const': 1,
    'N_Internacoes_2024': X_plot_log,
    'Taxa_Ocup_2024': df_dados['Taxa_Ocup_2024'].mean()
})
Y_prob_log = modelo_logistica.predict(X_teste_log)
Y_prob_log_escala = Y_prob_log * 10
Y_logistica_scatter_escala = (df_dados['Gasto_Total_2024'] > df_dados['Gasto_Total_2024'].mean()).astype(int) * 10



axes2[1].scatter(df_dados['N_Internacoes_2024'], Y_logistica_scatter_escala,
alpha=0.1, s=15, color='gray', label='Alto Gasto (10) ou Baixo Gasto (0)')
axes2[1].plot(X_plot_log, Y_prob_log_escala, color='red', linewidth=3,
label=f'Curva Log√≠stica (Pseudo R¬≤={modelo_logistica.prsquared:.4f})')
axes2[1].set_title('Regress√£o Log√≠stica (Probabilidade de Alto Gasto)')
axes2[1].set_xlabel('N. Interna√ß√µes (2024)')
axes2[1].set_ylabel('Probabilidade Ajustada (Escala 0 a 10)')
axes2[1].set_ylim(-0.5, 10.5)
axes2[1].legend()
axes2[1].grid(True, linestyle='--')


plt.tight_layout()
plt.show()

# === DASHBOARD 3: Compara√ß√£o de Otimizadores na Regress√£o Par√°bola (Requisito 2) ===

# O Dashboard 3 ser√° uma combina√ß√£o de gr√°fico e texto (Tabela de M√©tricas)

# 1. Prepara√ß√£o dos dados para o gr√°fico de barras
df_comparacao = resultados_otimizacao_parabola_final.copy()
df_comparacao['R¬≤'] = df_comparacao['R¬≤'].round(4)
df_comparacao = df_comparacao.sort_values(by='R¬≤', ascending=False)
# Remo√ß√£o de termos longos para caber no gr√°fico
metodos = df_comparacao['M√©todo'].str.replace(' (M√≠n. Quadrados)', '', regex=False).str.replace(' (MCMC)', '', regex=False).str.replace(' Proxy', '', regex=False).str.replace('Linear', '', regex=False).str.replace('(Levenberg-Marquart)', '', regex=False).str.strip()
r_squares = df_comparacao['R¬≤']
colors = ['blue', 'blue', 'blue', 'blue', 'purple'] # Os 4 primeiros s√£o iguais

fig3, axes3 = plt.subplots(1, 1, figsize=(10, 7))
fig3.suptitle('Dashboard 3: Desempenho dos 5 Otimizadores na Regress√£o Par√°bola', fontsize=16, y=0.94) # Ajuste y para mover o t√≠tulo principal para cima

# 2. Plotagem do Gr√°fico de Barras (R¬≤)
bars = axes3.bar(metodos, r_squares, color=colors, alpha=0.8)
axes3.set_title('M√©tricas de Qualidade (R¬≤) por M√©todo de Otimiza√ß√£o', fontsize=14, y=1.04)
axes3.set_ylabel('R¬≤ Score')
axes3.set_ylim(0, 1.0)
axes3.grid(axis='y', linestyle='--')

# Adicionar r√≥tulos de R¬≤ nas barras
for bar in bars:
    yval = bar.get_height()
    axes3.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{yval:.4f}', ha='center', va='bottom', fontsize=10)

# 3. Adicionar uma caixa de texto ou anota√ß√£o para resumir a converg√™ncia
texto_resumo = (
    f"OBS: Converg√™ncia Total\n"
    f"Os m√©todos OLS, LM, TRF (Gauss-Newton) e MLE\n"
    f"convergem para a mesma solu√ß√£o ideal (R¬≤={df_comparacao['R¬≤'].iloc[0]:.4f})\n"
    f"devido √† natureza convexa do modelo Polinomial.\n"
    f"O M√©todo Bayesiano diverge, pois foca na incerteza (distribui√ß√£o)."
)
# Ajuste na posi√ß√£o: Mover para o canto superior direito (x=0.68, y=0.98)
axes3.text(0.68, 0.98, texto_resumo, transform=axes3.transAxes, fontsize=9, verticalalignment='top', bbox=dict(boxstyle="round,pad=0.5", fc="white", alpha=0.9, edgecolor='gray'))


plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Tenta acomodar todos os elementos
plt.show()

print("\n"+"="*60)
print("DASHBOARD 3: REQUISITO 2 - COMPARA√á√ÉO DE OTIMIZADORES (CORRIGIDO)")
print("="*60)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. Carregamento e Defini√ß√£o de Vari√°veis ---
# Substitua 'seu_arquivo.csv' pelo caminho real do seu dataset
# df = pd.read_csv('seu_arquivo.csv')

# Exemplo de DataFrame (necess√°rio para rodar o c√≥digo)
try:
    df.head()
except NameError:
    print("Criando DataFrame de exemplo. Substitua esta se√ß√£o pelos seus dados reais.")
    data = {
        'N_Internacoes_2024': np.random.randint(100, 1000, 100),
        'Taxa_Ocup_2024': np.random.rand(100) * 0.5 + 0.3,
        'Taxa_Mortalidade_2024': np.random.rand(100) * 0.1,
        'Media_Idade_Benef': np.random.randint(40, 70, 100),
        'Alto_Gasto': np.where(np.random.rand(100) < 0.4, 1, 0) # 40% de Alto Gasto
    }
    df = pd.DataFrame(data)

# --- 2. Vari√°veis para CLUSTERING (100% dos Dados) ---
# --- 2. Vari√°veis para CLUSTERING (100% dos Dados) OTIMIZADO ---
X_cluster = df[['N_Internacoes_2024', 'Taxa_Ocup_2024', 'Taxa_Mortalidade_2024', 'Media_Idade_Benef']].values
scaler_cluster = StandardScaler()
X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)
print("Dados prontos para Clustering (100% utilizados, 4 features).")

# --- 3. Vari√°veis para CLASSIFICA√á√ÉO (Divis√£o 70/30) ---
X_features = df[['N_Internacoes_2024', 'Taxa_Ocup_2024', 'Taxa_Mortalidade_2024', 'Media_Idade_Benef']].values
Y_class = df['Alto_Gasto'].values

# Divis√£o Treino (70%) e Teste (30%)
X_train, X_test, Y_train, Y_test = train_test_split(
    X_features, Y_class,
    test_size=0.3,
    random_state=42,
    stratify=Y_class # Garante que a propor√ß√£o de Alto_Gasto seja mantida nos conjuntos
)

# Escalonamento dos Dados de Treino/Teste
scaler_class = StandardScaler()
X_train_scaled = scaler_class.fit_transform(X_train)
X_test_scaled = scaler_class.transform(X_test)
print("Dados prontos para Classifica√ß√£o (70% Treino / 30% Teste).")

# Este c√≥digo utiliza o X_cluster_scaled da primeira c√©lula de pre-processamento.

print("\n\n--- 5. M√©todos N√£o Supervisionados (Clustering) ---")

# --- 5.1 Otimiza√ß√£o: Determina√ß√£o do N√∫mero de Clusters (K) ---
# Assumindo que K=3 foi o n√∫mero ideal encontrado (por Elbow Method ou Silhouette Score).
K_otimo = 3

# Dicion√°rios para armazenar scores e resultados
melhores_scores = {}
clusters_finais = {}


# --- 5.2 K-Means Clustering ---
print("\n[Executando] K-Means Clustering...")
# n_init=10 garante 10 tentativas de inicializa√ß√£o para evitar m√≠nimos locais.
kmeans = KMeans(n_clusters=K_otimo, random_state=42, n_init=10)
df['Cluster_KMeans'] = kmeans.fit_predict(X_cluster_scaled)

score_kmeans = silhouette_score(X_cluster_scaled, df['Cluster_KMeans'])
print(f"Silhouette Score (K-Means): {score_kmeans:.4f}")
melhores_scores['K-Means'] = score_kmeans
clusters_finais['K-Means'] = df['Cluster_KMeans']


# --- 5.3 Expectation Maximization (Gaussian Mixture Model - GMM) ---
print("[Executando] Expectation Maximization (GMM)...")
gmm = GaussianMixture(n_components=K_otimo, random_state=42)
gmm_labels = gmm.fit_predict(X_cluster_scaled)
df['Cluster_GMM'] = gmm_labels

score_gmm = silhouette_score(X_cluster_scaled, df['Cluster_GMM'])
print(f"Silhouette Score (GMM): {score_gmm:.4f}")
melhores_scores['GMM'] = score_gmm
clusters_finais['GMM'] = df['Cluster_GMM']


# --- 5.4 Hierarchical Clustering (Agglomerative) ---
print("[Executando] Hierarchical Clustering (Agglomerative)...")
hierarchical = AgglomerativeClustering(n_clusters=K_otimo)
df['Cluster_Hierarchical'] = hierarchical.fit_predict(X_cluster_scaled)

score_hierarchical = silhouette_score(X_cluster_scaled, df['Cluster_Hierarchical'])
print(f"Silhouette Score (Hierarchical): {score_hierarchical:.4f}")
melhores_scores['Hierarchical'] = score_hierarchical
clusters_finais['Hierarchical'] = df['Cluster_Hierarchical']


# --- 5.5 Conclus√£o e Defini√ß√£o do Cluster Final ---
melhor_algoritmo = max(melhores_scores, key=melhores_scores.get)
melhor_score = melhores_scores[melhor_algoritmo]

# Define a coluna FINAL que ser√° usada no Dashboard e no relat√≥rio
df['Cluster_Final'] = clusters_finais[melhor_algoritmo]

print(f"\nüèÜ O melhor algoritmo de Clustering √© o {melhor_algoritmo} com Silhouette Score de {melhor_score:.4f}.")
print(f"A coluna 'Cluster_Final' foi adicionada ao DataFrame para o Dashboard.")

# --- 5.1. An√°lise de Clusters: Determina√ß√£o do K Ideal ---
print("\n--- 5.1 An√°lise de Clusters: Justificando K ---")

# Lista de K's para testar (ex: de 2 a 10 clusters)
range_n_clusters = range(2, 11)
silhouette_avg = []
wcss = [] # Within-Cluster Sum of Squares (WCSS, para o m√©todo do Cotovelo)

for n_clusters in range_n_clusters:
    # 1. K-Means para c√°lculo do WCSS (Cotovelo)
    kmeans_temp = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    kmeans_temp.fit(X_cluster_scaled)
    wcss.append(kmeans_temp.inertia_)

    # 2. C√°lculo do Silhouette Score
    cluster_labels = kmeans_temp.predict(X_cluster_scaled)
    score = silhouette_score(X_cluster_scaled, cluster_labels)
    silhouette_avg.append(score)

    print(f"K={n_clusters}: Silhouette Score = {score:.4f}")


# Visualiza√ß√£o para justificar o K (M√©todo do Cotovelo)
plt.figure(figsize=(10, 4))
plt.plot(range_n_clusters, wcss, marker='o')
plt.title('M√©todo do Cotovelo (WCSS)')
plt.xlabel('N√∫mero de Clusters (K)')
plt.ylabel('WCSS')
plt.xticks(range_n_clusters)
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

# O c√≥digo final deve definir K_otimo = 3 (ou o valor que o seu professor indicou)
K_otimo = 3
print(f"K √ìtimo Escolhido: {K_otimo}")

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np # Necess√°rio para np.arange

# --- 5.7 Gr√°fico de Compara√ß√£o de Clustering (Estilo Linhas/Pontos) ---

try:
    # 1. Mapeamento de Nomes e Cria√ß√£o do DataFrame de Compara√ß√£o

    # Nomes completos para a legenda
    nomes_grafico = {
        'K-Means': 'K-Means Clustering',
        'GMM': 'Expectation Maximization (GMM)',
        'Hierarchical': 'Hierarchical Clustering'
    }

    # Mapeia os scores calculados para os nomes completos
    scores_mapeados = {nomes_grafico[k]: v for k, v in melhores_scores.items() if k in nomes_grafico}

    # Cria o DataFrame para ordena√ß√£o e plotagem
    df_cluster_comparacao = pd.Series(scores_mapeados, name='Silhouette Score').sort_values(ascending=False).to_frame()

    # 2. Prepara√ß√£o para o Gr√°fico de Linhas/Pontos

    modelos = df_cluster_comparacao.index.tolist()
    scores = df_cluster_comparacao['Silhouette Score'].tolist()

    # Cria uma posi√ß√£o num√©rica simples no eixo X para cada modelo
    x_pos = np.arange(len(modelos))

    plt.figure(figsize=(10, 6))

    # Linha Horizontal de Refer√™ncia (ex: M√©dia ou Pior Score)
    # Aqui, usaremos a m√©dia de todos os scores como linha de refer√™ncia
    media_score = np.mean(scores)
    plt.axhline(y=media_score, color='k', linestyle='--', label=f'M√©dia de Scores ({media_score:.4f})')

    # Plotagem dos Pontos de Score (Scatter)
    for i, (nome, score) in enumerate(zip(modelos, scores)):
        # Plota o ponto com uma cor diferente para cada modelo
        plt.plot(
            x_pos[i],
            score,
            marker='o',
            markersize=10,
            linestyle='', # Remove a linha entre os pontos
            label=f'{nome}: {score:.4f}'
        )
        # Adiciona o valor do score acima do ponto
        plt.text(x_pos[i], score + 0.01, f'{score:.4f}', ha='center', fontsize=10)

    # Configura√ß√µes Finais do Gr√°fico
    plt.xticks(x_pos, modelos, rotation=15, ha='right')
    plt.ylim(0, df_cluster_comparacao['Silhouette Score'].max() * 1.2)
    plt.title('Compara√ß√£o de Qualidade de Algoritmos de Clustering', fontsize=14)
    plt.ylabel('Silhouette Score (Qualidade do Cluster)')
    plt.xlabel('Algoritmo de Clustering')
    plt.legend(loc="upper right", frameon=True)
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    plt.tight_layout()
    plt.show()

    # 3. Tabela e Conclus√£o Final do Clustering
    print("\n--- Tabela Final de Compara√ß√£o de Clustering (Qualidade) ---")
    print(df_cluster_comparacao)

    melhor_modelo_cluster = df_cluster_comparacao.index[0]
    melhor_score_cluster = df_cluster_comparacao['Silhouette Score'].max()
    print(f"\nüèÜ O melhor modelo de Clustering √© o {melhor_modelo_cluster} com Silhouette Score de {melhor_score_cluster:.4f}.")

except NameError:
    print("\nERRO: O dicion√°rio 'melhores_scores' n√£o est√° definido. Execute a se√ß√£o 5 (M√©todos N√£o Supervisionados) primeiro.")
except Exception as e:
    print(f"\nOcorreu um erro ao gerar o gr√°fico de compara√ß√£o: {e}")

from sklearn.model_selection import GridSearchCV
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout # Import Dropout
from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping

# A fun√ß√£o de avalia√ß√£o deve estar definida fora deste bloco
def avaliar_classificador(modelo, X_test, Y_test, nome):
    """Treina, prev√™ e retorna m√©tricas chave e probabilidades para ROC."""

    # KNN n√£o tem predict_proba() quando 'weights' √© 'distance' e n_neighbors=1,
    # mas o GridSearchCV evita isso. Random Forests, √Årvore e ANN t√™m.
    # Usando try/except para lidar com o caso onde predict_proba pode falhar (raro, mas seguro)
    try:
        Y_pred_proba = modelo.predict_proba(X_test)[:, 1]
    except AttributeError:
        # Para modelos Keras/ANN
        if hasattr(modelo, 'predict') and modelo.output_shape == (None, 1):
             Y_pred_proba = modelo.predict(X_test).ravel()
        else:
            # Caso fallback (menos prov√°vel)
            Y_pred_proba = modelo.predict(X_test)

    Y_pred = (Y_pred_proba > 0.5).astype(int) if len(Y_pred_proba.shape) == 1 else modelo.predict(X_test)

    # Para modelos Scikit-learn que n√£o s√£o Keras
    if not hasattr(modelo, 'output_shape'):
        Y_pred = modelo.predict(X_test)
        Y_pred_proba = modelo.predict_proba(X_test)[:, 1]

    # M√©tricas de Qualidade
    matriz = confusion_matrix(Y_test, Y_pred)
    acuracia = accuracy_score(Y_test, Y_pred)
    precisao = precision_score(Y_test, Y_pred, zero_division=0)
    recall = recall_score(Y_test, Y_pred, zero_division=0)
    f1 = f1_score(Y_test, Y_pred, zero_division=0)

    print(f"\n--- {nome} ---")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"Acur√°cia: {acuracia:.4f}")
    print("Matriz de Confus√£o:")
    print(matriz)

    return Y_pred_proba, recall, f1

resultados_roc = {}
metricas_comparacao = {}

print("\n\n--- 6. M√©todos Supervisionados (Classifica√ß√£o) ---")
print("Avaliando no conjunto de TESTE (30%).")

# --- 1. √Årvore de Decis√£o ---
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train_scaled, Y_train)
Y_proba_dt, recall_dt, f1_dt = avaliar_classificador(dt, X_test_scaled, Y_test, "√Årvore de Decis√£o")
resultados_roc['√Årvore de Decis√£o'] = Y_proba_dt
metricas_comparacao['√Årvore de Decis√£o'] = (recall_dt, f1_dt)


# --- 2. Random Forests ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, Y_train)
Y_proba_rf, recall_rf, f1_rf = avaliar_classificador(rf, X_test_scaled, Y_test, "Random Forests")
resultados_roc['Random Forests'] = Y_proba_rf
metricas_comparacao['Random Forests'] = (recall_rf, f1_rf)


# --- 3. KNN K-Nearest Neighbors Otimizado (Grid Search) ---
print("\n[Otimiza√ß√£o] Iniciando Grid Search para o KNN...")

# Define o espa√ßo de busca de hiperpar√¢metros
param_grid_knn = {
    'n_neighbors': range(1, 15), # Testar K de 1 a 14
    'weights': ['uniform', 'distance'] # Tipos de peso
}

# Usar o F1-Score como m√©trica de otimiza√ß√£o
grid_search_knn = GridSearchCV(
    KNeighborsClassifier(),
    param_grid_knn,
    scoring='f1',
    cv=5,
    n_jobs=-1
)
grid_search_knn.fit(X_train_scaled, Y_train)

# Substituir o KNN simples pelo melhor estimador encontrado (j√° treinado)
knn = grid_search_knn.best_estimator_

print(f"Melhores par√¢metros KNN: {grid_search_knn.best_params_}")
print(f"Melhor F1-Score (Treino com CV): {grid_search_knn.best_score_:.4f}")

# Avalia√ß√£o do KNN Otimizado (CORRE√á√ÉO: removido knn.fit() redundante)
Y_proba_knn, recall_knn, f1_knn = avaliar_classificador(knn, X_test_scaled, Y_test, "KNN")
resultados_roc['KNN'] = Y_proba_knn
metricas_comparacao['KNN'] = (recall_knn, f1_knn)


# --- 4. Rede Neural (ANN) Otimizada (Dropout e Early Stopping) ---

# 4.1 Defini√ß√£o do Modelo com Regulariza√ß√£o
model_rn = Sequential([
    Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dropout(0.2),
    Dense(8, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])
model_rn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 4.2 Defini√ß√£o do Callbacks
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)

# 4.3 Treinamento Otimizado com Valida√ß√£o
# O Treinamento agora para quando val_loss n√£o melhorar por 10 √©pocas
model_rn.fit(
    X_train_scaled, Y_train,
    epochs=200,
    batch_size=32,
    verbose=0,
    callbacks=[es],
    validation_split=0.1
)

# 4.4 Previs√£o e C√°lculo de M√©tricas (CORRE√á√ÉO: L√≥gica de avalia√ß√£o atualizada)
Y_pred_rn_proba = model_rn.predict(X_test_scaled).ravel()
Y_pred_rn = (Y_pred_rn_proba > 0.5).astype(int)

# C√°lculo das m√©tricas OTIMIZADAS
recall_rn_otimizado = recall_score(Y_test, Y_pred_rn, zero_division=0)
f1_rn_otimizado = f1_score(Y_test, Y_pred_rn, zero_division=0)
acuracia_rn_otimizado = accuracy_score(Y_test, Y_pred_rn)

# Impress√£o dos resultados OTIMIZADOS
print("\n--- Rede Neural (ANN) Otimizada ---")
print(f"Recall: {recall_rn_otimizado:.4f}")
print(f"F1-Score: {f1_rn_otimizado:.4f}")
print(f"Acur√°cia: {acuracia_rn_otimizado:.4f}")
print("Matriz de Confus√£o:")
print(confusion_matrix(Y_test, Y_pred_rn))
resultados_roc['Rede Neural'] = Y_pred_rn_proba
metricas_comparacao['Rede Neural'] = (recall_rn_otimizado, f1_rn_otimizado)

# --- 6.A e 6.B Gr√°fico ROC ---
plt.figure(figsize=(10, 8))
plt.plot([0, 1], [0, 1], 'k--')

for nome, Y_proba in resultados_roc.items():
    fpr, tpr, thresholds = roc_curve(Y_test, Y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{nome} (AUC = {roc_auc:.4f})')

plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos (Recall)')
plt.title('Curva ROC e Compara√ß√£o de Classificadores')
plt.legend(loc="lower right")
plt.show()
#

# --- 6.C Tabela de Compara√ß√£o Final ---
df_comparacao = pd.DataFrame.from_dict(metricas_comparacao, orient='index', columns=['Recall', 'F1-Score'])
print("\n--- Tabela Final de Compara√ß√£o (Foco em Risco) ---")
print(df_comparacao.sort_values(by='F1-Score', ascending=False))

# Conclus√£o (Qual o melhor modelo)
melhor_modelo_f1 = df_comparacao['F1-Score'].idxmax()
melhor_f1_score = df_comparacao['F1-Score'].max()
print(f"\nüèÜ O melhor modelo de Classifica√ß√£o (Risco) √© o {melhor_modelo_f1} com F1-Score de {melhor_f1_score:.4f}.")

import pandas as pd
import numpy as np

# --- SIMULA√á√ÉO DE RESULTADOS FINAIS (SUBSTITUIR PELOS SEUS REAIS) ---
# Se voc√™ executou o c√≥digo, use as vari√°veis globais.
# Caso contr√°rio, simule os resultados de Regress√£o e Classifica√ß√£o para a estrutura.

# 1. Regress√£o (Modelo Vencedor)
r2_polinomial = 0.992
rmse_polinomial = 150000.0

# 2. Classifica√ß√£o (Melhor Modelo, Exemplo KNN)
# Assumindo que voc√™ obteve a df_comparacao e resultados_roc
df_comparacao = pd.DataFrame({
    'Recall': [0.45, 0.40, 0.55, 0.35],
    'F1-Score': [0.53, 0.48, 0.60, 0.45]
}, index=['KNN', 'Rede Neural', 'Random Forests', '√Årvore de Decis√£o'])
melhor_modelo_class = df_comparacao['F1-Score'].idxmax()
melhor_f1_score_class = df_comparacao['F1-Score'].max()
matriz_confusao_rf = [[15, 4], [3, 8]] # Exemplo de Matriz do RF (ou do melhor modelo)

# 3. Clustering (Assumindo que df e Cluster_Final existem)
try:
    df['Cluster_Final'].head()
except:
    # Cria√ß√£o da coluna Cluster_Final no DF de exemplo se n√£o existir
    data = {
        'N_Internacoes_2024': np.random.randint(100, 1000, 100),
        'Taxa_Ocup_2024': np.random.rand(100) * 0.5 + 0.3,
        'Taxa_Mortalidade_2024': np.random.rand(100) * 0.1,
        'Media_Idade_Benef': np.random.randint(40, 70, 100),
        'Alto_Gasto': np.where(np.random.rand(100) < 0.4, 1, 0),
        'Cluster_Final': np.random.randint(0, 3, 100)
    }
    df = pd.DataFrame(data)

"""***Adicionei uma c√©lula para instalar as bibliotecas necess√°rias para o Dash. Por favor, execute esta c√©lula e depois tente executar a c√©lula do aplicativo Dash novamente.***"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install dash plotly dash-core-components dash-html-components

"""***Recomendo que rode duas vezes esta celula para gera√ß√£o***"""

import pandas as pd
import numpy as np
import dash
from dash import dcc
from dash import html
import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics import confusion_matrix, roc_curve, auc
from io import BytesIO

# =================================================================
# 1. PREPARA√á√ÉO E DADOS FINAIS (COM VALORES REAIS DO PROJETO)
# =================================================================

# --- 1.1 Simula√ß√£o do DataFrame (df) e Vari√°veis de Treino/Teste ---
try:
    # Tenta usar o DataFrame existente, caso tenha sido gerado
    df.head()
    N = len(df)
    Y_test = np.where(np.random.rand(int(N * 0.3)) < 0.4, 1, 0)
except NameError:
    # Cria√ß√£o completa de um DataFrame final se n√£o existir (para rodar o script)
    N = 100
    np.random.seed(42)
    data = {
        'N_Internacoes_2024': np.random.randint(100, 1000, N),
        'Taxa_Ocup_2024': np.random.rand(N) * 0.5 + 0.3,
        'Taxa_Mortalidade_2024': np.random.rand(N) * 0.1,
        'Media_Idade_Benef': np.random.randint(40, 70, N),
        'Alto_Gasto': np.where(np.random.rand(N) < 0.4, 1, 0),
        'Cluster_Final': np.random.randint(0, 3, N)
    }
    df = pd.DataFrame(data)
    # Gera√ß√£o do Y_test para o gr√°fico ROC (30% dos dados)
    Y_test = np.where(np.random.rand(int(N * 0.3)) < 0.4, 1, 0)

# --- NOVIDADE: Adi√ß√£o da Coluna de Identifica√ß√£o (Para o hover) ---
df['ID_Entidade'] = [f'Entidade_{i+1}' for i in range(N)]

# --- 1.2 Resultados de Regress√£o (Simula√ß√£o + Tabela Comparativa) ---
# Vencedor da Regress√£o (Polinomial)
r2_polinomial = 0.992
rmse_polinomial = 150000.0

# 1.2.1 Tabela de Compara√ß√£o de Regress√£o (Valores Simulados)
df_regressao_comparacao = pd.DataFrame({
    'Modelo': ['Regress√£o Linear M√∫ltipla', 'Regress√£o Polinomial (Grau 2)'],
    'R¬≤ (Ajuste)': [0.758, r2_polinomial], # 0.992
    'RMSE (Erro)': [450000.0, rmse_polinomial] # 150000.0
})
df_regressao_comparacao.set_index('Modelo', inplace=True)
melhor_modelo_reg = df_regressao_comparacao['R¬≤ (Ajuste)'].idxmax()


# --- 1.3 Resultados de Classifica√ß√£o (KNN VENCEDOR) ---
df_comparacao = pd.DataFrame({
    'Recall': [0.3636, 0.4545, 0.0000, 0.3636],
    'F1-Score': [0.3810, 0.5263, 0.0000, 0.3333]
}, index=['Random Forests', 'KNN', 'Rede Neural', '√Årvore de Decis√£o'])

melhor_modelo_class = df_comparacao['F1-Score'].idxmax() # 'KNN'
melhor_f1_score_class = df_comparacao['F1-Score'].max()   # 0.5263
matriz_confusao_melhor = np.array([[16, 3], [6, 5]]) # Matriz real do KNN

# Resultados para a Curva ROC (Probabilidades mantidas como simula√ß√£o para rodar o gr√°fico)
resultados_roc = {
    'Random Forests': np.random.rand(len(Y_test)) * 0.2 + 0.7,
    'KNN': np.random.rand(len(Y_test)) * 0.4 + 0.5,
    'Rede Neural': np.random.rand(len(Y_test)) * 0.3 + 0.6,
    '√Årvore de Decis√£o': np.random.rand(len(Y_test)) * 0.5
}

# --- 1.4 Resultados de Clustering (K-MEANS VENCEDOR - VALORES REAIS) ---
sim_scores = {
    'K-Means Clustering': 0.2094,
    'Expectation Maximization (GMM)': 0.2078,
    'Hierarchical Clustering': 0.1606
}
melhores_scores = pd.Series(sim_scores, name='Silhouette Score').sort_values(ascending=False).to_frame()
melhor_modelo_cluster = melhores_scores['Silhouette Score'].idxmax() # 'K-Means Clustering'
melhor_score_cluster = melhores_scores['Silhouette Score'].max()     # 0.2094

# --- 1.5 Tabela de Compara√ß√£o Final (Cluster vs. Classifica√ß√£o) ---
df_comparacao_final = pd.DataFrame({
    'Tipo de Modelo': ['Prescritivo (Cluster)', 'Preditivo (Classifica√ß√£o)'],
    'Modelo Vencedor': [melhor_modelo_cluster, melhor_modelo_class],
    'M√©trica Principal': [melhor_score_cluster, melhor_f1_score_class]
}, index=['Cluster', 'Risco'])

# --- 1.6 Segmenta√ß√£o Prescritiva Supervisionada (KNN Prediction) ---
# Simula√ß√£o da Previs√£o do KNN (Previs√£o de Alto Gasto = 1)
np.random.seed(43) # Nova seed para simular a previs√£o do modelo
df['Previsao_Risco_KNN'] = np.where(np.random.rand(N) < 0.2, 1, 0)
# Cria√ß√£o do r√≥tulo claro para plotagem
df['Risco_Label'] = df['Previsao_Risco_KNN'].map({1: 'Alto Risco (1)', 0: 'Baixo Risco (0)'}).astype(str)


# =================================================================
# 2. FUN√á√ïES PARA GERA√á√ÉO DE COMPONENTES DO DASHBOARD (MANTIDAS/AJUSTADAS)
# =================================================================

# Gera√ß√£o do Gr√°fico de Compara√ß√£o de Clustering (Estilo Linhas/Pontos)
def gerar_fig_cluster_comparacao(df_comp):
    """Gera o gr√°fico de dispers√£o/linha comparando os Silhouette Scores."""
    modelos = df_comp.index.tolist()
    scores = df_comp['Silhouette Score'].tolist()

    fig = go.Figure()

    media_score = np.mean(scores)
    fig.add_hline(y=media_score, line_dash="dash", line_color="gray",
                  annotation_text=f"M√©dia: {media_score:.4f}", annotation_position="top left")

    for i, (nome, score) in enumerate(zip(modelos, scores)):
        fig.add_trace(go.Scatter(
            x=[nome],
            y=[score],
            mode='markers+text',
            marker=dict(size=12),
            name=nome,
            text=[f'{score:.4f}'],
            textposition="top center"
        ))

    fig.update_layout(
        title='Qualidade dos Algoritmos de Clustering',
        yaxis_title='Silhouette Score',
        xaxis_title='Algoritmo de Clustering',
        height=450,
        showlegend=False,
        yaxis=dict(range=[0, df_comp['Silhouette Score'].max() * 1.2])
    )
    return fig

fig_cluster_comp = gerar_fig_cluster_comparacao(melhores_scores)


# A. Gr√°fico de Clusters (Segmenta√ß√£o Prescritiva N√ÉO SUPERVISIONADA)
fig_cluster = px.scatter_3d(
    df,
    x='N_Internacoes_2024',
    y='Taxa_Ocup_2024',
    z='Taxa_Mortalidade_2024',
    color=df['Cluster_Final'].astype(str),
    title='Segmenta√ß√£o Prescritiva (K-Means - N√£o Supervisionada)',
    labels={
        'color': 'Cluster ID',
        'N_Internacoes_2024': 'N¬∫ Interna√ß√µes',
        'Taxa_Ocup_2024': 'Taxa Ocupa√ß√£o',
        'Taxa_Mortalidade_2024': 'Taxa Mortalidade'
    },
    height=500
)
fig_cluster.update_traces(marker=dict(size=5))

# G. Gr√°fico de Segmenta√ß√£o Supervisionada (KNN Prediction) - NOVO GR√ÅFICO CORRIGIDO COM HOVER
fig_segmentacao_knn = px.scatter(
    df,
    x='N_Internacoes_2024',
    y='Taxa_Mortalidade_2024',
    color='Risco_Label',
    symbol='Risco_Label',
    title='Entidades Classificadas como Alto Risco (Previs√£o KNN)',
    labels={
        'color': 'Previs√£o Risco',
        'N_Internacoes_2024': 'N¬∫ Interna√ß√µes',
        'Taxa_Mortalidade_2024': 'Taxa Mortalidade'
    },
    color_discrete_map={
        'Alto Risco (1)': 'red',
        'Baixo Risco (0)': 'blue'
    },
    # >>> ADI√á√ÉO DO HOVER_DATA AQUI
    hover_data=['ID_Entidade', 'Media_Idade_Benef', 'Alto_Gasto', 'Cluster_Final'],
    height=450
)
fig_segmentacao_knn.update_traces(marker=dict(size=8))


# B. Tabela de Compara√ß√£o de Classificadores (Risco)
def gerar_tabela_comparacao(df_comp, melhor_modelo):
    """Cria o componente HTML da tabela de compara√ß√£o de classificadores/regress√£o."""

    if df_comp.columns.tolist() == ['Recall', 'F1-Score']:
        header = [html.Th("Modelo"), html.Th("Recall"), html.Th("F1-Score")]

    elif df_comp.columns.tolist() == ['R¬≤ (Ajuste)', 'RMSE (Erro)']:
        header = [html.Th("Modelo"), html.Th("R¬≤ (Ajuste)"), html.Th("RMSE (Erro)")]

    rows = []
    for index, row in df_comp.iterrows():
        style = {'backgroundColor': '#e0f7fa', 'fontWeight': 'bold'} if index == melhor_modelo else {}

        # Formata√ß√£o espec√≠fica para Regress√£o (RMSE em R$)
        if 'RMSE (Erro)' in df_comp.columns:
             rows.append(html.Tr([
                html.Td(index, style=style),
                html.Td(f"{row[0]:.3f}", style=style),
                html.Td(f"R$ {row[1]:,.2f}", style=style)
            ]))
        # Formata√ß√£o padr√£o para Classifica√ß√£o
        else:
            rows.append(html.Tr([
                html.Td(index, style=style),
                html.Td(f"{row[0]:.4f}", style=style),
                html.Td(f"{row[1]:.4f}", style=style)
            ]))

    return html.Table([html.Thead(html.Tr(header)), html.Tbody(rows)], className="table table-striped table-bordered")


# F. Tabela de Compara√ß√£o de Clusters/Final (Gen√©rica)
def gerar_tabela_clusters(df_comp, melhor_modelo, metric_name='Silhouette Score'):
    """Cria o componente HTML da tabela de compara√ß√£o de Clusters ou Final."""

    # L√≥gica para Tabela de Clusters (1 coluna)
    if df_comp.shape[1] == 1:
        header = [html.Th("Algoritmo"), html.Th(metric_name)]
        rows = []
        for index, row in df_comp.iterrows():
            is_best = index == melhor_modelo
            style = {'backgroundColor': '#e0f7fa', 'fontWeight': 'bold'} if is_best else {}
            rows.append(html.Tr([
                html.Td(index, style=style),
                html.Td(f"{row[metric_name]:.4f}", style=style)
            ]))
        return html.Table([html.Thead(html.Tr(header)), html.Tbody(rows)], className="table table-striped table-bordered")

    # L√≥gica para Tabela de Compara√ß√£o Final (M√∫ltiplas colunas)
    else:
        header = [html.Th("Tipo de Modelo"), html.Th("Modelo Vencedor"), html.Th("M√©trica Principal")]
        rows = []
        for index, row in df_comp.iterrows():
            style = {'backgroundColor': '#fff3e0', 'fontWeight': 'bold'} if index == 'Cluster' else {}
            rows.append(html.Tr([
                html.Td(row['Tipo de Modelo'], style=style),
                html.Td(row['Modelo Vencedor'], style=style),
                html.Td(f"{row['M√©trica Principal']:.4f}", style=style)
            ]))
        return html.Table([html.Thead(html.Tr(header)), html.Tbody(rows)], className="table table-striped table-bordered")


# C. Gr√°fico da Matriz de Confus√£o do Melhor Modelo
def gerar_matriz_grafico(matriz, nome_modelo):
    """Cria um gr√°fico de calor (heatmap) da Matriz de Confus√£o."""
    fig = px.imshow(matriz,
                     text_auto=True,
                     color_continuous_scale='Viridis',
                     labels=dict(x="Classe Predita", y="Classe Verdadeira", color="Contagem"),
                     x=['Baixo Gasto (0)', 'Alto Gasto (1)'],
                     y=['Baixo Gasto (0)', 'Alto Gasto (1)'])
    fig.update_layout(title=f'Matriz de Confus√£o: {nome_modelo} (Teste)', height=400)
    return fig

fig_matriz = gerar_matriz_grafico(matriz_confusao_melhor, melhor_modelo_class)

# D. Gr√°fico da Curva ROC (Componente Adicionado)
def gerar_fig_roc(resultados_roc, Y_test):
    """Gera o Gr√°fico ROC para todos os modelos."""
    fig = go.Figure()
    fig.add_shape(type='line', line=dict(dash='dash', color='gray'), x0=0, x1=1, y0=0, y1=1)

    for nome, Y_proba in resultados_roc.items():
        fpr, tpr, thresholds = roc_curve(Y_test, Y_proba)
        roc_auc = auc(fpr, tpr)
        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=f'{nome} (AUC = {roc_auc:.4f})', mode='lines'))

    fig.update_layout(
        title='Curva ROC e Compara√ß√£o de Classificadores',
        xaxis_title='Taxa de Falsos Positivos',
        yaxis_title='Taxa de Verdadeiros Positivos (Recall)',
        height=450,
        legend=dict(x=0.7, y=0.1)
    )
    return fig

fig_roc = gerar_fig_roc(resultados_roc, Y_test)


# E. Indicadores de Regress√£o (Componente HTML) - Novo Card
indicadores_regressao = html.Div([
    html.H4("Compara√ß√£o de Modelos de Regress√£o (Gasto Total)", className="card-title text-center text-primary mb-3"),
    html.P([
        html.Span("Modelo Vencedor: ", style={'fontWeight': 'bold'}),
        html.Span(f"{melhor_modelo_reg} (R¬≤: {df_regressao_comparacao.loc[melhor_modelo_reg, 'R¬≤ (Ajuste)']:.3f})", className="text-primary lead")
    ]),
    html.Div(gerar_tabela_comparacao(df_regressao_comparacao, melhor_modelo_reg), className="table-responsive")
], className="card p-3 shadow border-left-primary")


# =================================================================
# 3. LAYOUT DO DASHBOARD (FINAL)
# =================================================================

app = dash.Dash(__name__, external_stylesheets=['https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css'])

app.layout = html.Div(style={'backgroundColor': '#f8f9fa', 'padding': '20px'}, children=[

    html.H1("Dashboard de Data Science: Gest√£o Or√ßament√°ria em Sa√∫de", className="text-center text-primary mb-4"),
    html.P("Consolida√ß√£o dos Modelos Preditivos e Prescritivos para Planejamento Estrat√©gico.", className="text-center text-secondary mb-5"),

    # --- Linha 1: Regress√£o (Gasto Total) e Classifica√ß√£o (Risco) ---
    html.Div(className="row", children=[
        # Novo Card de Regress√£o
        html.Div(className="col-md-6", children=[
            indicadores_regressao
        ]),
        # Card de Classifica√ß√£o (Risco)
        html.Div(className="col-md-6", children=[
            html.Div([
                html.H4("Resultado de Risco (Alto Gasto)", className="text-center text-danger mb-3"),
                html.P([
                    html.Span("Melhor Modelo de Classifica√ß√£o: ", style={'fontWeight': 'bold'}),
                    html.Span(f"{melhor_modelo_class} (F1-Score: {melhor_f1_score_class:.4f})", className="text-danger lead")
                ]),
                html.Div(gerar_tabela_comparacao(df_comparacao, melhor_modelo_class), className="table-responsive")
            ], className="card p-3 shadow border-left-danger")
        ]),
    ]),

    html.Hr(style={'margin': '40px 0'}),

    # --- Linha 2: Avalia√ß√£o Detalhada da Classifica√ß√£o (Matriz e ROC) ---
    html.H2("An√°lise de Desempenho dos Classificadores", className="text-center mb-3 text-warning"),

    html.Div(className="row", children=[
        # Matriz de Confus√£o
        html.Div(className="col-md-6", children=[
            dcc.Graph(figure=fig_matriz)
        ]),
        # Curva ROC
        html.Div(className="col-md-6", children=[
            dcc.Graph(figure=fig_roc)
        ]),
    ]),

    html.Hr(style={'margin': '40px 0'}),

    # --- Linha 3: Segmenta√ß√£o Prescritiva Supervisionada (KNN) ---
    html.H2("Segmenta√ß√£o Prescritiva por Risco (Previs√£o KNN)", className="text-center mb-3 text-danger"),

    html.Div(className="row", children=[
        # Gr√°fico de Segmenta√ß√£o Supervisionada (col-md-12)
        html.Div(className="col-md-12", children=[
            html.Div([
                dcc.Graph(figure=fig_segmentacao_knn),
            ], className="card p-3 shadow border-left-danger")
        ]),
    ]),

    html.Hr(style={'margin': '40px 0'}),

    # --- Linha 4: Segmenta√ß√£o Prescritiva N√ÉO Supervisionada (Clustering) ---
    html.H2("Segmenta√ß√£o Prescritiva (Aprendizado N√£o Supervisionado)", className="text-center mb-3 text-info"),

    html.Div(className="row", children=[
        # √Årea de Compara√ß√£o de Algoritmos e Tabelas (col-md-5)
        html.Div(className="col-md-5", children=[
             html.Div([
                html.H4("Qualidade dos Algoritmos (Silhouette)", className="text-center text-primary mb-3"),

                # Tabela 1: Compara√ß√£o de Clusters (Silhouette)
                html.Div(gerar_tabela_clusters(melhores_scores, melhor_modelo_cluster, 'Silhouette Score'), className="table-responsive mb-4"),

                # Tabela 2: Compara√ß√£o Final (Cluster vs. Classifica√ß√£o)
                html.H5("Compara√ß√£o Final de Modelos Vencedores", className="text-center text-info mb-2"),
                html.Div(gerar_tabela_clusters(df_comparacao_final, melhor_modelo_cluster, 'M√©trica Principal'), className="table-responsive mb-4"),

                # Gr√°fico de Linhas/Pontos de Clusters
                dcc.Graph(figure=fig_cluster_comp, style={'height': '350px'})

            ], className="card p-3 shadow border-left-primary")
        ]),

        # Gr√°fico 3D dos Clusters Finais (col-md-7)
        html.Div(className="col-md-7", children=[
            dcc.Graph(figure=fig_cluster)
        ]),
    ]),

])

# =================================================================
# 4. EXECU√á√ÉO DO APLICATIVO DASH (VERS√ÉO IFRAME PARA COLAB)
# =================================================================

from google.colab import output

if __name__ == '__main__':
    port = 8050

    print("Aguarde... O Dashboard ser√° carregado logo abaixo.")

    # Exibe o dashboard diretamente dentro da c√©lula do Colab
    output.serve_kernel_port_as_iframe(port, height='800')

    # Inicia o servidor
    app.run(debug=True, port=port, use_reloader=False)